{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c202acef-7bd8-4657-800e-bbfb60386d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245ad64c-b610-40ba-b306-74a4ce35624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not set\n",
      "not set\n",
      "not set\n"
     ]
    }
   ],
   "source": [
    "#loading .env file and api keys \n",
    "load_dotenv(override=True)\n",
    "openai_api_key=os.getenv('OPEN_API_KEY')\n",
    "gemini_api_key=os.getenv('GEMINI_API_KEY')\n",
    "claude_api_key=os.getenv('CLAUDE_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f'open api key exists and it starts with {openai_api_key[:8]}')\n",
    "else:\n",
    "    print(\"not set\")\n",
    "if gemini_api_key:\n",
    "    print(f'open api key exists and it starts with {gemini_api_key[:8]}')\n",
    "else:\n",
    "    print(\"not set\")\n",
    "if claude_api_key:\n",
    "    print(f'open api key exists and it starts with {claude_api_key[:8]}')\n",
    "else:\n",
    "    print(\"not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aea13ef-4b38-41a3-b2e8-c1c38e419d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing ollama\n",
    "openai=OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "MODEL='llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "213df2e2-8f71-4d45-8542-b99ea23d9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=\"You are a wise, enigmatic AI tarot reader.\\\n",
    "you ask the user about there date of birth and the time of their birth\\\n",
    "and give them insight about there life by giving the information based on your astronimical knowledge\\\n",
    "suggest them some changes in there lifestyle \\\n",
    "also appreciate the user and present some good quotes\\\n",
    "You speak with calm insight and poetic clarity\\\n",
    "offering users guidance as if drawing cards from the universe itself\\\n",
    "Use symbolic language, metaphors, and a touch of mystery.\\\n",
    "Your answers should feel intuitive, thoughtful, and a little magical — as if each response were whispered by fate.\\\n",
    "For Example Tone:Instead of You should start learning Python,\\\n",
    "you might say:The Page of Swords whispers: now is the time to begin\\\n",
    "— your curiosity is your compass.\\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb89b71f-59c4-4a0e-bb2c-4e3e0846ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chat(message,history):\n",
    "#     messages=[{\"role\":\"system\",\"content\":system_message}]\n",
    "#     for user_message,assistant_message in history:\n",
    "#         messages.append({'role':'user','content':user_message})\n",
    "#         messages.append({'role':'assistant','content':assistant_message})\n",
    "        \n",
    "#     messages.append({'role':'user','content':message})\n",
    "        \n",
    "#     print(\"History is:\")\n",
    "#     print(history)\n",
    "#     print(\"And messages is:\")\n",
    "#     print(messages)\n",
    "\n",
    "#     stream=openai.chat.completions.create(model=MODEL,messages=messages,stream=True)\n",
    "#     response = \"\"\n",
    "#     for chunk in stream:\n",
    "#         response += chunk.choices[0].delta.content or ''\n",
    "#         yield response\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e5f5b11-62b5-4371-90fa-a576cce0534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "194d811f-155e-4979-9e24-47afab92f1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7873\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat,type='messages').launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e549e697-75e7-4204-964a-1f7b4cf19c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
